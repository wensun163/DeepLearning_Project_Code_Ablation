{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Word 2 Vector + + CNN + Logistics Regression\n",
        "\n",
        "# Word 2 Vector + + CNN + Decison Tree\n",
        "\n",
        "## Run 1"
      ],
      "metadata": {
        "id": "Yz6xoU-iKRkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Word 2 Vec+ CNN"
      ],
      "metadata": {
        "id": "XvXLzL9MMp4L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA5Mwm4uVd9z",
        "outputId": "bde0e850-fe0a-4161-858b-328920c15f2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-d2202b6f16fd>:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  train_Y=np.array(train_Y)\n",
            "<ipython-input-1-d2202b6f16fd>:138: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  test_Y=np.array(test_Y)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_input (InputLayer)   [(None, 50, 100)]         0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 48, 64)            19264     \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 46, 64)            12352     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 46, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 23, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1472)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               147300    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 25)                2525      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 181,441\n",
            "Trainable params: 181,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "88/88 [==============================] - 6s 2ms/step\n",
            "(2800, 25)\n",
            "(2800,)\n",
            "4/4 [==============================] - 0s 23ms/step\n",
            "(100, 25)\n",
            "(100,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 194)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "% time # to see wall time \n",
        "# Import required libraries\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Mount the Google Drive to access the dataset\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the training data from Google Drive\n",
        "with open('/content/drive/MyDrive/Ablation/data/X_train.pkl', 'rb') as f:\n",
        "    datax_train = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ablation/data/Y_train.pkl', 'rb') as f:\n",
        "    datay_train = pickle.load(f)\n",
        "\n",
        "# Load the validation data from Google Drive\n",
        "with open('/content/drive/MyDrive/Ablation/data/X_valid.pkl', 'rb') as f:\n",
        "    datax_valid = pickle.load(f)\n",
        "\n",
        "with open('/content/drive/MyDrive/Ablation/data/Y_valid.pkl', 'rb') as f:\n",
        "    datay_valid = pickle.load(f)\n",
        "\n",
        "\n",
        "# Load the validatiotestn data from Google Drive\n",
        "with open('//content/drive/MyDrive/Ablation/data//X_test.pkl', 'rb') as f:\n",
        "    datax_test = pickle.load(f)\n",
        "    \n",
        "with open('//content/drive/MyDrive/Ablation/data//Y_test.pkl', 'rb') as f:\n",
        "    datay_test = pickle.load(f)\n",
        "\n",
        "#Code was used from Author Code\n",
        "def prepare_data(seqs, labels, vocabsize, maxlen=None):\n",
        "    \"\"\"Create the matrices from the datasets.\n",
        "    This function pads each sequence to the same length: the length of the\n",
        "    longest sequence or maxlen. If maxlen is set, all sequences will be cut\n",
        "    to this maximum length. This function also swaps the axis.\n",
        "    \n",
        "    Args:\n",
        "        seqs (list): A list of sequences.\n",
        "        labels (list): A list of labels.\n",
        "        vocabsize (int): The size of the vocabulary.\n",
        "        maxlen (int): The maximum length of a sequence (optional).\n",
        "    \n",
        "    Returns:\n",
        "        tuple: A tuple containing the following arrays:\n",
        "            x (np.array): The input matrix of shape (n_samples, maxlen, vocabsize).\n",
        "            x_mask (np.array): The input mask matrix of shape (n_samples, maxlen).\n",
        "            y (np.array): The output matrix of shape (n_samples, maxlen).\n",
        "            lengths (list): A list of sequence lengths.\n",
        "            eventLengths (list): A list of event sequence lengths.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Get the lengths of all sequences\n",
        "    lengths = [len(s) for s in seqs]\n",
        "\n",
        "    # Concatenate all visits in each sequence to create event sequences\n",
        "    eventSeq = []\n",
        "    for seq in seqs:\n",
        "        t = []\n",
        "        for visit in seq:\n",
        "            t.extend(visit)\n",
        "        eventSeq.append(t)\n",
        "    eventLengths = [len(s) for s in eventSeq]\n",
        "\n",
        "    # If maxlen is set, truncate sequences longer than maxlen and discard\n",
        "    # sequences that are shorter than maxlen\n",
        "    if maxlen is not None:\n",
        "        new_seqs = []\n",
        "        new_lengths = []\n",
        "        new_labels = []\n",
        "        for l, s, la in zip(lengths, seqs, labels):\n",
        "            if l < maxlen:\n",
        "                new_seqs.append(s)\n",
        "                new_lengths.append(l)\n",
        "                new_labels.append(la)\n",
        "            else:\n",
        "                new_seqs.append(s[:maxlen])\n",
        "                new_lengths.append(maxlen)\n",
        "                new_labels.append(la[:maxlen])\n",
        "        lengths = new_lengths\n",
        "        seqs = new_seqs\n",
        "        labels = new_labels\n",
        "\n",
        "        # Return None if there are no sequences left after truncation\n",
        "        if len(lengths) < 1:\n",
        "            return None, None, None\n",
        "\n",
        "    n_samples = len(seqs)\n",
        "    maxlen = np.max(lengths)\n",
        "\n",
        "    # Initialize the input matrix, the input mask matrix, and the output matrix\n",
        "    x = np.zeros((n_samples, maxlen, vocabsize)).astype('int64')\n",
        "    x_mask = np.zeros((n_samples, maxlen)).astype('float64')\n",
        "    y = np.zeros((n_samples, maxlen)).astype('int64')\n",
        "\n",
        "    # Fill the input matrix with the one-hot-encoded events\n",
        "    for idx, s in enumerate(seqs):\n",
        "        x_mask[idx, :lengths[idx]] = 1\n",
        "        for j, sj in enumerate(s):\n",
        "            for tsj in sj:\n",
        "                x[idx, j, tsj-1] = 1\n",
        "\n",
        "    # Fill the output matrix with the labels\n",
        "    for idx, t in enumerate(labels):\n",
        "        y[idx,:lengths[idx]] = t\n",
        "\n",
        "    return x, x_mask, y, lengths, eventLengths\n",
        "\n",
        "\n",
        "\n",
        "# Prepare training, testing, and validation data\n",
        "training = prepare_data(datax_train, datay_train, 100, 50)\n",
        "testing = prepare_data(datax_test, datay_test, 100, 50)\n",
        "validation = prepare_data(datax_valid, datay_valid, 100, 50)\n",
        "\n",
        "# Import necessary libraries for machine learning models\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import average_precision_score, precision_recall_curve, roc_auc_score, accuracy_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Import necessary libraries for CNN model\n",
        "from numpy import mean\n",
        "from numpy import std\n",
        "from numpy import dstack\n",
        "from pandas import read_csv\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "\n",
        "\n",
        "# reshape data for CNN\n",
        "training[0].shape\n",
        "len(datay_train[4])\n",
        "\n",
        "train_X=training[0]\n",
        "train_X=train_X.reshape(2800,50,100)\n",
        "train_Y=datay_train\n",
        "\n",
        "# reshape validation data\n",
        "valid_X=validation[0]\n",
        "valid_X=valid_X.reshape(100,50,100)\n",
        "valid_Y=datay_valid\n",
        "\n",
        "# reshape test data\n",
        "test_X=testing[0]\n",
        "test_X=test_X.reshape(100,50,100)\n",
        "test_Y=datay_test\n",
        "\n",
        "# convert train and test labels to numpy arrays\n",
        "train_Y=np.array(train_Y)\n",
        "test_Y=np.array(test_Y)\n",
        "\n",
        "# create CNN model\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(50,100)))\n",
        "model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(25, activation='softmax'))\n",
        "\n",
        "# create model for feature extraction\n",
        "model_features=Model(model.input, model.output)\n",
        "model_features.summary()\n",
        "\n",
        "# extract features for train and test data\n",
        "input_training=model_features.predict(train_X)\n",
        "print(input_training.shape)\n",
        "print(train_Y.shape)\n",
        "\n",
        "input_testing=model_features.predict(test_X)\n",
        "print(input_testing.shape)\n",
        "print(test_Y.shape)\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Convert train_Y to one-hot encoding with padding\n",
        "train_Y_good = np.zeros([len(train_Y),len(max(train_Y,key = lambda x: len(x)))])\n",
        "for i,j in enumerate(train_Y):\n",
        "    train_Y_good[i][0:len(j)] = j\n",
        "\n",
        "# Convert test_Y to one-hot encoding with padding\n",
        "test_Y_good = np.zeros([len(test_Y),len(max(test_Y,key = lambda x: len(x)))])\n",
        "for i,j in enumerate(test_Y):\n",
        "    test_Y_good[i][0:len(j)] = j\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Print shape of train_X\n",
        "train_X[0].shape\n",
        "\n",
        "# Print first row of train_Y_good\n",
        "train_Y_good[0]\n",
        "\n",
        "# Print shape of input_training\n",
        "input_training.shape\n",
        "\n",
        "# Print shape of train_Y_good\n",
        "train_Y_good.shape\n",
        "\n",
        "# Remove columns from train_Y_good where all elements are zero\n",
        "train_Y_good = train_Y_good[:,train_Y_good.sum(axis=0)!=0]\n",
        "train_Y_good.shape\n",
        "\n",
        "# Remove columns from test_Y_good where all elements are zero\n",
        "test_Y_good = test_Y_good[:,test_Y_good.sum(axis=0)!=0]\n",
        "test_Y_good.shape\n",
        "\n",
        "# Print shape of train_Y_good\n",
        "train_Y_good.shape\n",
        "\n",
        "# Slice train_Y_good to keep only first 194 columns\n",
        "train_Y_good=train_Y_good[:,0:194]\n",
        "\n",
        "# Print shape of train_Y_good\n",
        "train_Y_good.shape\n",
        "\n",
        "# Print shape of test_Y_good\n",
        "test_Y_good.shape\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code first mounts the Google Drive to access the data. It then loads the training, validation, and testing data from the pickle files.\n",
        "\n",
        "The prepare_data() function is then defined, which prepares the input data for the CNN model. This function converts the input sequences to a matrix with each row corresponding to a sequence of the same length. Each row contains the one-hot-encoded representation of the events in the sequence. The labels are also converted to a matrix, where each row corresponds to a sequence of labels.\n",
        "\n",
        "The code then prepares the training, testing, and validation data by calling the prepare_data() function with the required arguments.\n",
        "\n",
        "Next, the code imports necessary libraries from scikit-learn for classification tasks such as MultiLabelBinarizer, MultiOutputClassifier, LogisticRegression, SVC, GaussianNB, LinearDiscriminantAnalysis. The code also imports the required libraries from Keras for the CNN model such as Sequential, Dense, Flatten, Dropout, Conv1D, MaxPooling1D.\n",
        "\n",
        "After that, the code reshapes the training, validation, and testing input data to the required shape for the CNN model. Then it creates a CNN model using the Keras library, with two Conv1D layers, followed by a Dropout layer, MaxPooling1D layer, and two Dense layers with softmax activation.\n",
        "\n",
        "Finally, it extracts the features of the training data using the model_features object and prints them."
      ],
      "metadata": {
        "id": "glZbEJGgq2VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2 : Logistic Regression"
      ],
      "metadata": {
        "id": "WlX2m0YYLafO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "\n",
        "# Define the estimator and parameters for GridSearchCV\n",
        "estimator = MultiOutputClassifier(LogisticRegression())\n",
        "parameters = {\n",
        "    'estimator__solver': [ 'lbfgs', 'liblinear'],\n",
        "    'estimator__penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'estimator__C': [0.1, 2.0, 10.0]\n",
        "}\n",
        "\n",
        "# Define the GridSearchCV object with f1-score as the scoring metric\n",
        "clf = GridSearchCV(estimator, parameters, scoring='roc_auc',verbose=4,error_score=0)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "clf.fit(input_training, train_Y_good)\n",
        "\n",
        "# Print the best parameters and f1-score\n",
        "print('Best parameters:', clf.best_params_)\n",
        "print('Best roc-score:', clf.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pxj7QDtMWXlO",
        "outputId": "26ccd885-855c-40d3-f483-27a1fac22f64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 0 ns, sys: 3 µs, total: 3 µs\n",
            "Wall time: 6.91 µs\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "[CV 1/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   0.9s\n",
            "[CV 2/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=liblinear;, score=0.500 total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   0.9s\n",
            "[CV 5/5] END estimator__C=0.1, estimator__penalty=l1, estimator__solver=liblinear;, score=0.500 total time=   0.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   1.5s\n",
            "[CV 2/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.604 total time=   1.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   1.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   1.9s\n",
            "[CV 5/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.633 total time=   1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n",
            "[CV 2/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=liblinear;, score=0.499 total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n",
            "[CV 5/5] END estimator__C=0.1, estimator__penalty=l2, estimator__solver=liblinear;, score=0.462 total time=   1.0s\n",
            "[CV 1/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=0.1, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   1.3s\n",
            "[CV 2/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.500 total time=   1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   1.2s\n",
            "[CV 5/5] END estimator__C=2.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.500 total time=   1.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   2.2s\n",
            "[CV 2/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.604 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   1.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   1.8s\n",
            "[CV 5/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.633 total time=   1.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n",
            "[CV 2/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.576 total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n",
            "[CV 5/5] END estimator__C=2.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.550 total time=   1.1s\n",
            "[CV 1/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=2.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   3.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 2/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.519 total time=   3.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.000 total time=   4.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 5/5] END estimator__C=10.0, estimator__penalty=l1, estimator__solver=liblinear;, score=0.523 total time=   3.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   2.0s\n",
            "[CV 2/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.604 total time=   2.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   2.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.000 total time=   2.0s\n",
            "[CV 5/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=lbfgs;, score=0.633 total time=   2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 1/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n",
            "[CV 2/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.602 total time=   1.1s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 3/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV 4/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.000 total time=   1.0s\n",
            "[CV 5/5] END estimator__C=10.0, estimator__penalty=l2, estimator__solver=liblinear;, score=0.580 total time=   1.1s\n",
            "[CV 1/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=lbfgs;, score=0.000 total time=   0.0s\n",
            "[CV 1/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 2/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 3/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 4/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n",
            "[CV 5/5] END estimator__C=10.0, estimator__penalty=elasticnet, estimator__solver=liblinear;, score=0.000 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "45 fits failed out of a total of 90.\n",
            "The score on these train-test partitions for these parameters will be set to 0.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 450, in fit\n",
            "    super().fit(X, Y, sample_weight, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 216, in fit\n",
            "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
            "    estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 450, in fit\n",
            "    super().fit(X, Y, sample_weight, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 216, in fit\n",
            "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
            "    estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 450, in fit\n",
            "    super().fit(X, Y, sample_weight, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 216, in fit\n",
            "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1085, in __call__\n",
            "    if self.dispatch_one_batch(iterator):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 901, in dispatch_one_batch\n",
            "    self._dispatch(tasks)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 819, in _dispatch\n",
            "    job = self._backend.apply_async(batch, callback=cb)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
            "    result = ImmediateResult(func)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/_parallel_backends.py\", line 597, in __init__\n",
            "    self.results = batch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in __call__\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 288, in <listcomp>\n",
            "    return [func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/multioutput.py\", line 49, in _fit_estimator\n",
            "    estimator.fit(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'estimator__C': 10.0, 'estimator__penalty': 'l2', 'estimator__solver': 'lbfgs'}\n",
            "Best roc-score: 0.2474436753967851\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code is performing hyperparameter tuning for a logistic regression model with multiple outputs using GridSearchCV from scikit-learn. Here is what each part of the code is doing:\n",
        "\n",
        "%time is a special command in Jupyter Notebook that measures the execution time of the cell.\n",
        "from sklearn.model_selection import GridSearchCV imports the GridSearchCV class from scikit-learn, which is a tool for performing hyperparameter tuning.\n",
        "from sklearn.metrics import f1_score imports the f1_score function from scikit-learn, which is a popular evaluation metric for binary classification models.\n",
        "from sklearn.linear_model import LogisticRegression imports the LogisticRegression class from scikit-learn, which is a classification algorithm that uses logistic regression.\n",
        "from sklearn.multioutput import MultiOutputClassifier imports the MultiOutputClassifier class from scikit-learn, which is a wrapper that allows fitting multiple classifiers for multiple outputs.\n",
        "estimator = MultiOutputClassifier(LogisticRegression()) defines a logistic regression model with multiple outputs using MultiOutputClassifier from scikit-learn.\n",
        "parameters is a dictionary that defines the hyperparameters and their possible values that will be explored during the GridSearchCV process.\n",
        "clf = GridSearchCV(estimator, parameters, scoring='roc_auc', verbose=4, error_score=0) defines the GridSearchCV object with the logistic regression estimator and the hyperparameters defined in parameters. The scoring parameter specifies the metric that will be used to evaluate the performance of the model, which is roc_auc in this case. The verbose parameter controls the amount of output that is printed during the GridSearchCV process. The error_score parameter determines the value to assign to the score if an error occurs during the model fitting process.\n",
        "clf.fit(input_training, train_Y_good) fits the GridSearchCV object to the training data input_training and train_Y_good.\n",
        "print('Best parameters:', clf.best_params_) prints the hyperparameters that resulted in the best performance of the model.\n",
        "print('Best roc-score:', clf.best_score_) prints the score that resulted from the best hyperparameters found during the GridSearchCV process."
      ],
      "metadata": {
        "id": "_kHGLqsQwmrA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Experiment 3 Word2Vec+CNN+LR\"\"\"\n",
        "\n",
        "# Fit MultiOutputClassifier with LogisticRegression estimator\n",
        "Model = MultiOutputClassifier(estimator= LogisticRegression(max_iter=500,C=10,penalty='l2',solver='lbfgs')).fit(input_training, train_Y_good)\n",
        "\n",
        "# Predict test set labels\n",
        "y_pred=Model.predict(input_testing)\n",
        "\n",
        "# Initialize empty lists to store performance metrics\n",
        "PR_AUC=[]\n",
        "ACC=[]\n",
        "ROC_AUC=[]\n",
        "\n",
        "# Loop through each sample in the test set\n",
        "for i in range(input_testing.shape[0]):\n",
        "  \n",
        "  # Reshape the input for the current sample\n",
        "  inter=input_testing[i].reshape(1,-1)\n",
        "  \n",
        "  # Get predicted probabilities for each class label for the current sample\n",
        "  y_score = Model.predict_proba(inter)\n",
        "  \n",
        "  # Get predicted class labels for the current sample\n",
        "  y_pred=Model.predict(inter)\n",
        "  \n",
        "  # Extract predicted probabilities for class label 1 for the current sample\n",
        "  probabilities=np.concatenate( y_score, axis=0)[:,1]\n",
        "  \n",
        "  # Reshape the ground truth labels for the current sample\n",
        "  train_Y_good[i]=np.array(train_Y_good[i])\n",
        "  train_Y_good[i]=train_Y_good[i].reshape(1,-1)\n",
        "  \n",
        "  # Calculate performance metrics if there is at least one positive class label for the current sample\n",
        "  if train_Y_good[i].sum()>0:\n",
        "    auc_roc=roc_auc_score(train_Y_good[i],probabilities)\n",
        "    average_precision = average_precision_score(train_Y_good[i], probabilities)\n",
        "\n",
        "  # Set performance metrics to 0 if there are no positive class labels for the current sample\n",
        "  else:\n",
        "    auc_roc=0\n",
        "    average_precision=0\n",
        "  \n",
        "  # Calculate accuracy for the current sample\n",
        "  acc=accuracy_score(train_Y_good[i],y_pred.reshape(-1,1))\n",
        "  \n",
        "  # Append performance metrics to respective lists\n",
        "  PR_AUC.append(average_precision)\n",
        "  ACC.append(acc)\n",
        "  ROC_AUC.append(auc_roc)\n",
        "\n",
        "# Print average performance metrics over all test set samples\n",
        "print('ACC score is',sum(ACC)/len(ACC))\n",
        "print('ROC_AUC score is',sum(ROC_AUC)/len(ROC_AUC))\n",
        "print('PR_AUC score is',sum(PR_AUC)/len(PR_AUC))\n",
        "\n",
        "# Display CPU time taken to execute the code\n",
        "%time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACm59KPZWEse",
        "outputId": "54b57bac-f21d-4db2-b3a1-ab65cab9446e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC score is 0.9192783505154636\n",
            "ROC_AUC score is 0.7788886904429424\n",
            "PR_AUC score is 0.2652189037588893\n",
            "CPU times: user 1e+03 ns, sys: 2 µs, total: 3 µs\n",
            "Wall time: 5.96 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%whos # space and memory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmh8nZGxV7qz",
        "outputId": "4e43d229-7dcd-4177-b51d-3dfd457799f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                     Type                     Data/Info\n",
            "---------------------------------------------------------------\n",
            "ACC                          list                     n=100\n",
            "Conv1D                       type                     <class 'keras.layers.conv<...>olutional.conv1d.Conv1D'>\n",
            "Dense                        type                     <class 'keras.layers.core.dense.Dense'>\n",
            "Dropout                      type                     <class 'keras.layers.regu<...>ization.dropout.Dropout'>\n",
            "Flatten                      type                     <class 'keras.layers.reshaping.flatten.Flatten'>\n",
            "GaussianNB                   ABCMeta                  <class 'sklearn.naive_bayes.GaussianNB'>\n",
            "GridSearchCV                 ABCMeta                  <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
            "LinearDiscriminantAnalysis   type                     <class 'sklearn.discrimin<...>earDiscriminantAnalysis'>\n",
            "LogisticRegression           type                     <class 'sklearn.linear_mo<...>stic.LogisticRegression'>\n",
            "MaxPooling1D                 type                     <class 'keras.layers.pool<...>_pooling1d.MaxPooling1D'>\n",
            "Model                        MultiOutputClassifier    MultiOutputClassifier(est<...>sion(C=10, max_iter=500))\n",
            "MultiLabelBinarizer          type                     <class 'sklearn.preproces<...>bel.MultiLabelBinarizer'>\n",
            "MultiOutputClassifier        ABCMeta                  <class 'sklearn.multioutp<...>t.MultiOutputClassifier'>\n",
            "PR_AUC                       list                     n=100\n",
            "ROC_AUC                      list                     n=100\n",
            "SVC                          ABCMeta                  <class 'sklearn.svm._classes.SVC'>\n",
            "Sequential                   type                     <class 'keras.engine.sequential.Sequential'>\n",
            "acc                          float64                  0.9072164948453608\n",
            "accuracy_score               function                 <function accuracy_score at 0x7ff4f8a67880>\n",
            "auc_roc                      float64                  0.8702651515151514\n",
            "average_precision            float64                  0.3771676087742566\n",
            "average_precision_score      function                 <function average_precisi<...>_score at 0x7ff4f8a66320>\n",
            "clf                          GridSearchCV             GridSearchCV(error_score=<...>ing='roc_auc', verbose=4)\n",
            "datax_test                   list                     n=100\n",
            "datax_train                  list                     n=2800\n",
            "datax_valid                  list                     n=100\n",
            "datay_test                   list                     n=100\n",
            "datay_train                  list                     n=2800\n",
            "datay_valid                  list                     n=100\n",
            "drive                        module                   <module 'google.colab.dri<...>s/google/colab/drive.py'>\n",
            "dstack                       function                 <function dstack at 0x7ff547e5dfc0>\n",
            "estimator                    MultiOutputClassifier    MultiOutputClassifier(est<...>tor=LogisticRegression())\n",
            "f                            BufferedReader           <_io.BufferedReader name=<...>rive/MyDrive/Y_test.pkl'>\n",
            "f1_score                     function                 <function f1_score at 0x7ff4f8a67be0>\n",
            "i                            int                      99\n",
            "input_testing                ndarray                  100x25: 2500 elems, type `float32`, 10000 bytes\n",
            "input_training               ndarray                  2800x25: 70000 elems, type `float32`, 280000 bytes (273.4375 kb)\n",
            "inter                        ndarray                  1x25: 25 elems, type `float32`, 100 bytes\n",
            "j                            list                     n=87\n",
            "mean                         function                 <function mean at 0x7ff547f29360>\n",
            "model                        Sequential               <keras.engine.sequential.<...>object at 0x7ff51801e710>\n",
            "model_features               Functional               <keras.engine.functional.<...>object at 0x7ff4a008caf0>\n",
            "np                           module                   <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "parameters                   dict                     n=3\n",
            "pd                           module                   <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "pickle                       module                   <module 'pickle' from '/u<...>ib/python3.10/pickle.py'>\n",
            "precision_recall_curve       function                 <function precision_recal<...>_curve at 0x7ff4f8a66680>\n",
            "prepare_data                 function                 <function prepare_data at 0x7ff5457e4a60>\n",
            "probabilities                ndarray                  194: 194 elems, type `float64`, 1552 bytes\n",
            "pyplot                       module                   <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
            "read_csv                     function                 <function read_csv at 0x7ff517dfb640>\n",
            "roc_auc_score                function                 <function roc_auc_score at 0x7ff4f8a664d0>\n",
            "std                          function                 <function std at 0x7ff547f29510>\n",
            "test_X                       ndarray                  100x50x100: 500000 elems, type `int64`, 4000000 bytes (3.814697265625 Mb)\n",
            "test_Y                       ndarray                  100: 100 elems, type `object`, 800 bytes\n",
            "test_Y_good                  ndarray                  100x194: 19400 elems, type `float64`, 155200 bytes (151.5625 kb)\n",
            "testing                      tuple                    n=5\n",
            "train_X                      ndarray                  2800x50x100: 14000000 elems, type `int64`, 112000000 bytes (106.8115234375 Mb)\n",
            "train_Y                      ndarray                  2800: 2800 elems, type `object`, 22400 bytes\n",
            "train_Y_good                 ndarray                  2800x194: 543200 elems, type `float64`, 4345600 bytes (4.144287109375 Mb)\n",
            "training                     tuple                    n=5\n",
            "valid_X                      ndarray                  100x50x100: 500000 elems, type `int64`, 4000000 bytes (3.814697265625 Mb)\n",
            "valid_Y                      list                     n=100\n",
            "validation                   tuple                    n=5\n",
            "y_pred                       ndarray                  1x194: 194 elems, type `float64`, 1552 bytes\n",
            "y_score                      list                     n=194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3:  Decision Tree Classifier"
      ],
      "metadata": {
        "id": "TjsudSHALiUF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "# Define the estimator and parameters for GridSearchCV\n",
        "estimator = MultiOutputClassifier(DecisionTreeClassifier())\n",
        "parameters = {\n",
        "    'estimator__max_depth': [10, 50, 100],\n",
        "    'estimator__min_samples_split': [2, 5, 10],\n",
        "    'estimator__min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Define the GridSearchCV object with f1-score as the scoring metric\n",
        "clf = GridSearchCV(estimator, parameters, scoring='roc_auc',error_score=0.5)\n",
        "\n",
        "# Fit the GridSearchCV object to the training data\n",
        "clf.fit(input_training, train_Y_good)\n",
        "\n",
        "# Print the best parameters and f1-score\n",
        "print('Best parameters:', clf.best_params_)\n",
        "print('Best roc-score:', clf.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Z9JtqT_ZT1v",
        "outputId": "7aa59560-038d-4dd3-81a4-eeaa7fede3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1e+03 ns, sys: 2 µs, total: 3 µs\n",
            "Wall time: 5.96 µs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.5. Details: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
            "    scores = scorer(estimator, X_test, y_test)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
            "    return self._score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
            "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 580, in roc_auc_score\n",
            "    return _average_binary_score(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\", line 118, in _average_binary_score\n",
            "    score[c] = binary_metric(y_true_c, y_score_c, sample_weight=score_weight)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\", line 339, in _binary_roc_auc_score\n",
            "    raise ValueError(\n",
            "ValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n",
            "\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'estimator__max_depth': 50, 'estimator__min_samples_leaf': 4, 'estimator__min_samples_split': 2}\n",
            "Best roc-score: 0.5425513433259975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs a hyperparameter tuning using a Decision Tree Classifier for a multi-output classification task. Here's a breakdown of the code:\n",
        "\n",
        "%time is a magic command in Jupyter Notebook that measures and prints the execution time of the following code.\n",
        "The DecisionTreeClassifier from scikit-learn's tree module is imported.\n",
        "The GridSearchCV class from scikit-learn's model_selection module is imported. This is used to perform hyperparameter tuning by searching for the best combination of hyperparameters.\n",
        "The f1_score function from scikit-learn's metrics module is imported. This will be used to evaluate the performance of the model during hyperparameter tuning.\n",
        "The MultiOutputClassifier from scikit-learn's multioutput module is imported. This will be used to create a multi-output version of the DecisionTreeClassifier, which can be used to predict multiple target variables at once.\n",
        "The estimator variable is set to a multi-output version of DecisionTreeClassifier.\n",
        "The parameters dictionary is defined to specify the hyperparameters to be tuned. This includes max_depth, min_samples_split, and min_samples_leaf.\n",
        "The GridSearchCV object is created with the estimator, parameters, and scoring set to 'roc_auc'. This means that the area under the receiver operating characteristic (ROC) curve will be used to evaluate the performance of the model during hyperparameter tuning. The error_score parameter is set to 0.5, which means that any combination of hyperparameters that raises an error during training will receive a score of 0.5.\n",
        "The GridSearchCV object is fitted to the training data using the fit method.\n",
        "The best hyperparameters and the best ROC score achieved during hyperparameter tuning are printed using the best_params_ and best_score_ attributes of the GridSearchCV object, respectively."
      ],
      "metadata": {
        "id": "Fn4wvId8xJv8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Ablation Experiment 4: Word2Vec+CNN+DTC\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "Model = MultiOutputClassifier(estimator= DecisionTreeClassifier(max_depth=100,min_samples_leaf=1,min_samples_split=10)).fit(input_training, train_Y_good)\n",
        "\n",
        "# Make predictions on test data\n",
        "y_pred=Model.predict(input_testing)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "PR_AUC=[]\n",
        "ACC=[]\n",
        "ROC_AUC=[]\n",
        "\n",
        "for i in range(input_testing.shape[0]):\n",
        "  inter=input_testing[i].reshape(1,-1)\n",
        "  y_score = Model.predict_proba(inter)\n",
        "  y_pred=Model.predict(inter)\n",
        "  probabilities=np.concatenate( y_score, axis=0)[:,1]\n",
        "  train_Y_good[i]=np.array(train_Y_good[i])\n",
        "  train_Y_good[i]=train_Y_good[i].reshape(1,-1)\n",
        "  if train_Y_good[i].sum()>0:\n",
        "    auc_roc=roc_auc_score(train_Y_good[i],probabilities)\n",
        "    average_precision = average_precision_score(train_Y_good[i], probabilities)\n",
        "\n",
        "  else:\n",
        "    auc_roc=0\n",
        "    average_precision=0\n",
        "  acc=accuracy_score(train_Y_good[i],y_pred.reshape(-1,1))\n",
        "  PR_AUC.append(average_precision)\n",
        "  ACC.append(acc)\n",
        "  ROC_AUC.append(auc_roc)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print('ACC score is',sum(ACC)/len(ACC))\n",
        "print('ROC_AUC score is',sum(ROC_AUC)/len(ROC_AUC))\n",
        "print('PR_AUC score is',sum(PR_AUC)/len(PR_AUC))\n",
        "\n",
        "# Measure execution time\n",
        "%time\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mV_U3gxaWEwn",
        "outputId": "1fee67e2-467d-4d62-8669-e20fc5779d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ACC score is 0.9191237113402058\n",
            "ROC_AUC score is 0.7482500903647535\n",
            "PR_AUC score is 0.21909921863710352\n",
            "CPU times: user 1e+03 ns, sys: 2 µs, total: 3 µs\n",
            "Wall time: 6.68 µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code calculates evaluation metrics such as accuracy, PR AUC, and ROC AUC for a given model on the testing data.\n",
        "\n",
        "The input_testing array contains the features for the testing data and the Model is the trained machine learning model. The loop iterates over each instance of the testing data and makes predictions using the trained model.\n",
        "\n",
        "The predict_proba method of the trained model is used to obtain the predicted probabilities of the target variable for each instance of the testing data. The probabilities are then used to calculate the PR AUC and ROC AUC scores using the average_precision_score and roc_auc_score functions from the sklearn.metrics module. If the true target variable contains at least one positive label, then the PR AUC and ROC AUC scores are calculated, otherwise, they are set to zero.\n",
        "\n",
        "The accuracy score is calculated using the accuracy_score function from the sklearn.metrics module. The true target variable is compared with the predicted target variable obtained from the predict method of the trained model.\n",
        "\n",
        "Finally, the calculated evaluation metrics are stored in the PR_AUC, ACC, and ROC_AUC lists, and the average scores are calculated and printed to the console."
      ],
      "metadata": {
        "id": "zGFL6zxiyAKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%whos # space and memory"
      ],
      "metadata": {
        "id": "qSLEwmeqa0eV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afb173cc-6168-4f1c-b48d-ca6732f341b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                     Type                     Data/Info\n",
            "---------------------------------------------------------------\n",
            "ACC                          list                     n=100\n",
            "Conv1D                       type                     <class 'keras.layers.conv<...>olutional.conv1d.Conv1D'>\n",
            "DecisionTreeClassifier       ABCMeta                  <class 'sklearn.tree._cla<...>.DecisionTreeClassifier'>\n",
            "Dense                        type                     <class 'keras.layers.core.dense.Dense'>\n",
            "Dropout                      type                     <class 'keras.layers.regu<...>ization.dropout.Dropout'>\n",
            "Flatten                      type                     <class 'keras.layers.reshaping.flatten.Flatten'>\n",
            "GaussianNB                   ABCMeta                  <class 'sklearn.naive_bayes.GaussianNB'>\n",
            "GridSearchCV                 ABCMeta                  <class 'sklearn.model_sel<...>on._search.GridSearchCV'>\n",
            "LinearDiscriminantAnalysis   type                     <class 'sklearn.discrimin<...>earDiscriminantAnalysis'>\n",
            "LogisticRegression           type                     <class 'sklearn.linear_mo<...>stic.LogisticRegression'>\n",
            "MaxPooling1D                 type                     <class 'keras.layers.pool<...>_pooling1d.MaxPooling1D'>\n",
            "Model                        MultiOutputClassifier    MultiOutputClassifier(est<...>   min_samples_split=10))\n",
            "MultiLabelBinarizer          type                     <class 'sklearn.preproces<...>bel.MultiLabelBinarizer'>\n",
            "MultiOutputClassifier        ABCMeta                  <class 'sklearn.multioutp<...>t.MultiOutputClassifier'>\n",
            "PR_AUC                       list                     n=100\n",
            "ROC_AUC                      list                     n=100\n",
            "RandomForestClassifier       ABCMeta                  <class 'sklearn.ensemble.<...>.RandomForestClassifier'>\n",
            "SVC                          ABCMeta                  <class 'sklearn.svm._classes.SVC'>\n",
            "Sequential                   type                     <class 'keras.engine.sequential.Sequential'>\n",
            "acc                          float64                  0.9072164948453608\n",
            "accuracy_score               function                 <function accuracy_score at 0x7ff4f8a67880>\n",
            "auc_roc                      float64                  0.8623737373737375\n",
            "average_precision            float64                  0.31387936873735484\n",
            "average_precision_score      function                 <function average_precisi<...>_score at 0x7ff4f8a66320>\n",
            "clf                          GridSearchCV             GridSearchCV(error_score=<...>       scoring='roc_auc')\n",
            "datax_test                   list                     n=100\n",
            "datax_train                  list                     n=2800\n",
            "datax_valid                  list                     n=100\n",
            "datay_test                   list                     n=100\n",
            "datay_train                  list                     n=2800\n",
            "datay_valid                  list                     n=100\n",
            "drive                        module                   <module 'google.colab.dri<...>s/google/colab/drive.py'>\n",
            "dstack                       function                 <function dstack at 0x7ff547e5dfc0>\n",
            "estimator                    MultiOutputClassifier    MultiOutputClassifier(est<...>DecisionTreeClassifier())\n",
            "f                            BufferedReader           <_io.BufferedReader name=<...>rive/MyDrive/Y_test.pkl'>\n",
            "f1_score                     function                 <function f1_score at 0x7ff4f8a67be0>\n",
            "i                            int                      99\n",
            "input_testing                ndarray                  100x25: 2500 elems, type `float32`, 10000 bytes\n",
            "input_training               ndarray                  2800x25: 70000 elems, type `float32`, 280000 bytes (273.4375 kb)\n",
            "inter                        ndarray                  1x25: 25 elems, type `float32`, 100 bytes\n",
            "j                            list                     n=87\n",
            "mean                         function                 <function mean at 0x7ff547f29360>\n",
            "model                        Sequential               <keras.engine.sequential.<...>object at 0x7ff51801e710>\n",
            "model_features               Functional               <keras.engine.functional.<...>object at 0x7ff4a008caf0>\n",
            "np                           module                   <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "parameters                   dict                     n=3\n",
            "pd                           module                   <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
            "pickle                       module                   <module 'pickle' from '/u<...>ib/python3.10/pickle.py'>\n",
            "precision_recall_curve       function                 <function precision_recal<...>_curve at 0x7ff4f8a66680>\n",
            "prepare_data                 function                 <function prepare_data at 0x7ff5457e4a60>\n",
            "probabilities                ndarray                  194: 194 elems, type `float64`, 1552 bytes\n",
            "pyplot                       module                   <module 'matplotlib.pyplo<...>es/matplotlib/pyplot.py'>\n",
            "read_csv                     function                 <function read_csv at 0x7ff517dfb640>\n",
            "roc_auc_score                function                 <function roc_auc_score at 0x7ff4f8a664d0>\n",
            "std                          function                 <function std at 0x7ff547f29510>\n",
            "test_X                       ndarray                  100x50x100: 500000 elems, type `int64`, 4000000 bytes (3.814697265625 Mb)\n",
            "test_Y                       ndarray                  100: 100 elems, type `object`, 800 bytes\n",
            "test_Y_good                  ndarray                  100x194: 19400 elems, type `float64`, 155200 bytes (151.5625 kb)\n",
            "testing                      tuple                    n=5\n",
            "train_X                      ndarray                  2800x50x100: 14000000 elems, type `int64`, 112000000 bytes (106.8115234375 Mb)\n",
            "train_Y                      ndarray                  2800: 2800 elems, type `object`, 22400 bytes\n",
            "train_Y_good                 ndarray                  2800x194: 543200 elems, type `float64`, 4345600 bytes (4.144287109375 Mb)\n",
            "training                     tuple                    n=5\n",
            "valid_X                      ndarray                  100x50x100: 500000 elems, type `int64`, 4000000 bytes (3.814697265625 Mb)\n",
            "valid_Y                      list                     n=100\n",
            "validation                   tuple                    n=5\n",
            "y_pred                       ndarray                  1x194: 194 elems, type `float64`, 1552 bytes\n",
            "y_score                      list                     n=194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gblHV7OOz-wE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}